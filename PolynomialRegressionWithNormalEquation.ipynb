{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAWVish78lxn"
      },
      "source": [
        "# Polynomial Regression from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqm8RQaKA_w8",
        "outputId": "9fda8866-3b78-4609-9b88-f14e74e350a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: 859529.1472389 \tReal: 841644\n",
            "Predicted: 62475.57063326441 \tReal: 67719\n",
            "Predicted: 23364.784083362305 \tReal: 25475\n",
            "Predicted: 16865.098660285636 \tReal: 18984\n",
            "Predicted: 68336.60443502475 \tReal: 73542\n",
            "Predicted: 28765.877648908427 \tReal: 33447\n",
            "Predicted: 274802.22452111426 \tReal: 305541\n",
            "Predicted: 82102.54144312371 \tReal: 87538\n",
            "Predicted: 53319.93485401559 \tReal: 59477\n",
            "Predicted: 68791.53297499056 \tReal: 83130\n",
            "Average Percentage Accuracy: 87.0214832928066\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class PolynomialRegression:\n",
        "    def __init__(self, degree=2, method='normal_equation', lr=0.001, iterations=10000):\n",
        "        self.degree = degree\n",
        "        self.method = method\n",
        "        self.lr = lr\n",
        "        self.iterations = iterations\n",
        "        self.weights = None\n",
        "\n",
        "    def create_polynomial_features(self, X):\n",
        "        poly_features = [X]\n",
        "        for d in range(2, self.degree + 1):\n",
        "            poly_features.append(X.pow(d))\n",
        "        return pd.concat(poly_features, axis=1)\n",
        "\n",
        "    def normal_equation(self, X, y):\n",
        "        X_transpose = np.transpose(X)\n",
        "        X_transpose_X = np.dot(X_transpose, X)\n",
        "        X_transpose_y = np.dot(X_transpose, y)\n",
        "     \n",
        "        try:\n",
        "            theta = np.linalg.solve(X_transpose_X, X_transpose_y)\n",
        "            return theta\n",
        "        except np.linalg.LinAlgError:\n",
        "            return None\n",
        "\n",
        "    # def gradient_descent(self, X, y):\n",
        "    #     weights = np.ones((X.shape[1], 1), dtype=np.float32)\n",
        "    #     m = X.shape[0]\n",
        "\n",
        "    #     for _ in range(self.iterations):\n",
        "    #         predictions = np.zeros((972,20))\n",
        "    #         errors = predictions - y\n",
        "    #         gradient = np.dot(X.T, errors) / m\n",
        "    #         theta = theta - self.lr * gradient\n",
        "    #     return weights\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_poly = self.create_polynomial_features(X)\n",
        "        if self.method == 'normal_equation':\n",
        "            self.weights = self.normal_equation(X_poly, y)\n",
        "        elif self.method == 'gradient_descent':\n",
        "            self.weights = self.gradient_descent(X_poly, y)\n",
        "        else:\n",
        "            raise ValueError(\"Method must be 'normal_equation' or 'gradient_descent'\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_poly = self.create_polynomial_features(X)\n",
        "        return np.dot(X_poly,self.weights)\n",
        "\n",
        "# Verileri yükleme ve hazırlama\n",
        "data = pd.read_csv('processed_dataset.csv')\n",
        "\n",
        "# Kategorik değişkeni sayısal değere dönüştürme\n",
        "le = LabelEncoder()\n",
        "data['city'] = le.fit_transform(data['city'])\n",
        "\n",
        "# Drop non-feature columns from the DataFrame\n",
        "X = data.drop(columns=['opened_inside_year','carried_over_from','finished','carried_over_to'])\n",
        "\n",
        "# Separate the target variable\n",
        "y = data['opened_inside_year']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# First 81 row is the year 2021\n",
        "X_train, X_test, y_train, y_test = X.iloc[81:], X.iloc[:81], y.iloc[81:], y.iloc[:81]\n",
        "\n",
        "# Normal Equation ile model oluşturma ve eğitme\n",
        "model_ne = PolynomialRegression(degree=4, method='normal_equation')\n",
        "model_ne.fit(X_train, y_train)\n",
        "\n",
        "# Tahminler\n",
        "y_pred_ne = model_ne.predict(X_test)\n",
        "\n",
        "# Print predicted and real y-values for the first 10 rows\n",
        "for i in range(10):\n",
        "    print(\"Predicted:\", y_pred_ne[i], \"\\tReal:\", y_test.iloc[i])\n",
        "\n",
        "# Calculate absolute percentage error for each prediction\n",
        "absolute_percentage_errors = np.abs((y_test - y_pred_ne) / y_test)\n",
        "\n",
        "# Calculate mean absolute percentage error\n",
        "mape = np.mean(absolute_percentage_errors)\n",
        "\n",
        "# Convert MAPE to accuracy (accuracy = 1 - MAPE)\n",
        "accuracy = 1 - mape\n",
        "\n",
        "# Convert accuracy to percentage\n",
        "percentage_accuracy = accuracy * 100\n",
        "\n",
        "print(\"Average Percentage Accuracy:\", percentage_accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
