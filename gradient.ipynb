{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fca47c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent Predictions:\n",
      "Predicted: 100082.58562952575 \tReal: 103840.0\n",
      "Predicted: 64946.493421606996 \tReal: 67719.0\n",
      "Predicted: 25309.654981168278 \tReal: 25475.0\n",
      "Predicted: 17256.140438355655 \tReal: 18984.0\n",
      "Predicted: 71315.91449542914 \tReal: 73542.0\n",
      "Predicted: 31055.363723227652 \tReal: 33447.0\n",
      "Predicted: 100099.88433619076 \tReal: 103840.0\n",
      "Predicted: 87188.96141311279 \tReal: 87538.0\n",
      "Predicted: 55949.956460654525 \tReal: 59477.0\n",
      "Predicted: 72519.6888824062 \tReal: 83130.0\n",
      "Average Percentage Accuracy (Gradient Descent): 91.60710178816727\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "class PolynomialRegression:\n",
    "    def __init__(self, degree=2, method='gradient_descent', lr=0.001, iterations=10000):\n",
    "        self.degree = degree\n",
    "        self.method = method\n",
    "        self.lr = lr\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def create_polynomial_features(self, X):\n",
    "        poly_features = [np.ones(X.shape[0])]  # Sabit terim (bias)\n",
    "        for d in range(1, self.degree + 1):\n",
    "            poly_features.append(X ** d)\n",
    "        return np.column_stack(poly_features)\n",
    "\n",
    "    def gradient_descent(self, X, y):\n",
    "        theta = np.random.randn(X.shape[1])\n",
    "        m = X.shape[0]\n",
    "\n",
    "        for iteration in range(self.iterations):\n",
    "            predictions = np.dot(X, theta)\n",
    "            errors = predictions - y\n",
    "            gradient = np.dot(X.T, errors) / m\n",
    "            theta_new = theta - self.lr * gradient\n",
    "            \n",
    "            if np.linalg.norm(theta_new - theta) < 1e-6:\n",
    "                print(f\"Converged at iteration {iteration}\")\n",
    "                break\n",
    "            \n",
    "            theta = theta_new\n",
    "        return theta\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_poly = self.create_polynomial_features(X)\n",
    "    \n",
    "        if self.method == 'gradient_descent':\n",
    "            self.weights = self.gradient_descent(X_poly, y)\n",
    "        else:\n",
    "            raise ValueError(\"'method' should be 'gradient_descent'\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_poly = self.create_polynomial_features(X)\n",
    "        return np.dot(X_poly, self.weights)\n",
    "\n",
    "# Verileri yükleme ve hazırlama\n",
    "data = pd.read_csv('processed_dataset.csv')\n",
    "\n",
    "# Kategorik değişkeni sayısal değere dönüştürme\n",
    "le = LabelEncoder()\n",
    "data['city'] = le.fit_transform(data['city'])\n",
    "\n",
    "# Aykırı değerleri işleme\n",
    "def handle_outliers_iqr_all_columns(data):\n",
    "    for column_name in data.columns:\n",
    "        Q1 = data[column_name].quantile(0.25)  # Alt çeyrek (25. yüzdelik)\n",
    "        Q3 = data[column_name].quantile(0.75)  # Üst çeyrek (75. yüzdelik)\n",
    "        IQR = Q3 - Q1  # IQR hesaplama\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR  # Alt sınır\n",
    "        upper_bound = Q3 + 1.5 * IQR  # Üst sınır\n",
    "\n",
    "        # Alt sınırın altındaki ve üst sınırın üstündeki aykırı değerleri çeyrekler arası aralığa getirme\n",
    "        data[column_name] = data[column_name].apply(lambda x: lower_bound if x < lower_bound else (upper_bound if x > upper_bound else x))\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = handle_outliers_iqr_all_columns(data)\n",
    "\n",
    "# Özellik ve hedef değişkenleri ayırma\n",
    "X = data.drop(columns=['opened_inside_year','carried_over_from','finished','carried_over_to']).values\n",
    "y = data['opened_inside_year'].values\n",
    "\n",
    "# Verileri normalleştirme\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Veriyi eğitim ve test setlerine ayırma\n",
    "# İlk 81 satır 2021 yılına aittir\n",
    "X_train, X_test, y_train, y_test = X_scaled[81:], X_scaled[:81], y[81:], y[:81]\n",
    "\n",
    "# Gradient Descent ile model oluşturma ve eğitme\n",
    "model_gd = PolynomialRegression(degree=2, method='gradient_descent', lr=0.1, iterations=1000)\n",
    "model_gd.fit(X_train, y_train)\n",
    "\n",
    "# Tahminler\n",
    "y_pred_gd = model_gd.predict(X_test)\n",
    "\n",
    "# İlk 10 satır için tahmin edilen ve gerçek y değerlerini yazdırma (gradient descent)\n",
    "print(\"Gradient Descent Predictions:\")\n",
    "for i in range(10):\n",
    "    print(\"Predicted:\", y_pred_gd[i], \"\\tReal:\", y_test[i])\n",
    "\n",
    "# Her tahmin için mutlak yüzde hatasını hesaplama (gradient descent)\n",
    "absolute_percentage_errors_gd = np.abs((y_test - y_pred_gd) / y_test)\n",
    "\n",
    "# Ortalama mutlak yüzde hatasını hesaplama (gradient descent)\n",
    "mape_gd = np.mean(absolute_percentage_errors_gd)\n",
    "\n",
    "# MAPE'yi doğruluğa dönüştürme (gradient descent)\n",
    "accuracy_gd = 1 - mape_gd\n",
    "\n",
    "# Doğruluğu yüzdeye dönüştürme (gradient descent)\n",
    "percentage_accuracy_gd = accuracy_gd * 100\n",
    "\n",
    "print(\"Average Percentage Accuracy (Gradient Descent):\", percentage_accuracy_gd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8c829db",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:38\u001b[1;36m\u001b[0m\n\u001b[1;33m    def fit(self, X, y):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class PolynomialRegression:\n",
    "    def __init__(self, degree=2, method='normal_equation', lr=0.001, iterations=10000):\n",
    "        self.degree = degree\n",
    "        self.method = method\n",
    "        self.lr = lr\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def create_polynomial_features(self, X):\n",
    "        poly_features = [np.ones(X.shape[0])]  # Sabit terim (bias)\n",
    "        for d in range(1, self.degree + 1):\n",
    "            poly_features.append(X ** d)\n",
    "        return np.column_stack(poly_features)\n",
    "\n",
    "    def gradient_descent(self, X, y):\n",
    "        theta = np.random.randn(X.shape[1])\n",
    "        m = X.shape[0]\n",
    "\n",
    "        for iteration in range(self.iterations):\n",
    "            predictions = np.dot(X, theta)\n",
    "            errors = predictions - y\n",
    "            gradient = np.dot(X.T, errors) / m\n",
    "            theta_new = theta - self.lr * gradient\n",
    "            \n",
    "            if np.linalg.norm(theta_new - theta) < 1e-6:\n",
    "                print(f\"Converged at iteration {iteration}\")\n",
    "                break\n",
    "            \n",
    "            theta = theta_new\n",
    "        return theta\n",
    "\n",
    "     def fit(self, X, y):\n",
    "        X_poly = self.create_polynomial_features(X)\n",
    "    \n",
    "        if self.method == 'gradient_descent':\n",
    "            self.weights = self.gradient_descent(X_poly, y)\n",
    "        else:\n",
    "            raise ValueError(\"'method' should be 'gradient_descent'\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_poly = self.create_polynomial_features(X)\n",
    "        return np.dot(X_poly, self.weights)\n",
    "\n",
    "# Verileri yükleme ve hazırlama\n",
    "data = pd.read_csv('processed_dataset.csv')\n",
    "\n",
    "# Kategorik değişkeni sayısal değere dönüştürme\n",
    "le = LabelEncoder()\n",
    "data['city'] = le.fit_transform(data['city'])\n",
    "\n",
    "# Aykırı değerleri işleme\n",
    "def handle_outliers_iqr_all_columns(data):\n",
    "    for column_name in data.columns:\n",
    "        Q1 = data[column_name].quantile(0.25)  # Alt çeyrek (25. yüzdelik)\n",
    "        Q3 = data[column_name].quantile(0.75)  # Üst çeyrek (75. yüzdelik)\n",
    "        IQR = Q3 - Q1  # IQR hesaplama\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR  # Alt sınır\n",
    "        upper_bound = Q3 + 1.5 * IQR  # Üst sınır\n",
    "\n",
    "        # Alt sınırın altındaki ve üst sınırın üstündeki aykırı değerleri çeyrekler arası aralığa getirme\n",
    "        data[column_name] = data[column_name].apply(lambda x: lower_bound if x < lower_bound else (upper_bound if x > upper_bound else x))\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = handle_outliers_iqr_all_columns(data)\n",
    "\n",
    "# Özellik ve hedef değişkenleri ayırma\n",
    "X = data.drop(columns=['opened_inside_year','carried_over_from','finished','carried_over_to']).values\n",
    "y = data['opened_inside_year'].values\n",
    "\n",
    "# Verileri normalleştirme\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA uygulama\n",
    "pca = PCA(n_components=4)  # Kaç bileşen kullanılacak\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# PCA sonrası bileşenlerin dağılımını kontrol etme\n",
    "print(\"PCA sonrası bileşenlerin dağılımı:\")\n",
    "print(X_pca[:10])  # İlk 10 örneğin bileşen değerlerini yazdırma\n",
    "\n",
    "# Veriyi eğitim ve test setlerine ayırma\n",
    "# İlk 81 satır 2021 yılına aittir\n",
    "X_train, X_test, y_train, y_test = X_pca[81:], X_pca[:81], y[81:], y[:81]\n",
    "\n",
    "# Gradient Descent ile model oluşturma ve eğitme\n",
    "# Öğrenme oranını daha küçük bir değere ayarlayarak deneyin\n",
    "model_gd = PolynomialRegression(degree=2, method='gradient_descent', lr=0.01, iterations=1000)\n",
    "model_gd.fit(X_train, y_train)\n",
    "\n",
    "# Tahminler\n",
    "y_pred_gd = model_gd.predict(X_test)\n",
    "\n",
    "# İlk 10 satır için tahmin edilen ve gerçek y değerlerini yazdırma (gradient descent)\n",
    "print(\"Gradient Descent Predictions:\")\n",
    "for i in range(10):\n",
    "    print(\"Predicted:\", y_pred_gd[i], \"\\tReal:\", y_test[i])\n",
    "\n",
    "# Her tahmin için mutlak yüzde hatasını hesaplama (gradient descent)\n",
    "absolute_percentage_errors_gd = np.abs((y_test - y_pred_gd) / y_test)\n",
    "\n",
    "# Ortalama mutlak yüzde hatasını hesaplama (gradient descent)\n",
    "mape_gd = np.mean(absolute_percentage_errors_gd)\n",
    "\n",
    "# MAPE'yi doğruluğa dönüştürme (gradient descent)\n",
    "accuracy_gd = 1 - mape_gd\n",
    "\n",
    "# Doğruluğu yüzdeye dönüştürme (gradient descent)\n",
    "percentage_accuracy_gd = accuracy_gd * 100\n",
    "\n",
    "print(\"Average Percentage Accuracy (Gradient Descent):\", percentage_accuracy_gd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d8126a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA sonrası bileşenlerin dağılımı:\n",
      "[[ 4.04503133  0.8438743  -1.7561251   0.03569797 -0.08655409]\n",
      " [ 2.11554961  0.42507407 -1.75895007  0.60491666  0.34246759]\n",
      " [-0.44220761 -1.2927094  -1.22862457  0.2363895   0.11023636]\n",
      " [-0.74799604 -0.4485998  -1.64086241  0.06180665 -0.04454804]\n",
      " [ 1.48849157 -1.93268471 -0.81041489 -0.45815851  0.2775129 ]\n",
      " [-0.23658852  0.55337757 -2.1010855  -0.44992996  0.13275606]\n",
      " [ 4.046167    0.88182612 -1.77404967  0.02769094 -0.08505912]\n",
      " [ 2.27819023 -1.92677972 -0.75792197  0.14022227  0.91477641]\n",
      " [ 0.96522309 -1.48336472 -1.03509193 -0.2127999   0.12485653]\n",
      " [ 1.32670081 -0.36444288 -1.60780627 -0.77782868  0.70753209]]\n",
      "Gradient Descent Predictions:\n",
      "Predicted: 105598.79058640542 \tReal: 103840.0\n",
      "Predicted: 61446.563092625714 \tReal: 67719.0\n",
      "Predicted: 24651.137829764783 \tReal: 25475.0\n",
      "Predicted: 18494.23754085901 \tReal: 18984.0\n",
      "Predicted: 69650.25370095864 \tReal: 73542.0\n",
      "Predicted: 32644.40732769314 \tReal: 33447.0\n",
      "Predicted: 105780.25945460753 \tReal: 103840.0\n",
      "Predicted: 80969.50246108828 \tReal: 87538.0\n",
      "Predicted: 53494.633858680565 \tReal: 59477.0\n",
      "Predicted: 66637.53698705099 \tReal: 83130.0\n",
      "Average Percentage Accuracy (Gradient Descent): 80.04119639103858\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class PolynomialRegression:\n",
    "    def __init__(self, degree=2, method='gradient_descent', lr=0.001, iterations=10000):\n",
    "        self.degree = degree\n",
    "        self.method = method\n",
    "        self.lr = lr\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def create_polynomial_features(self, X):\n",
    "        poly_features = [np.ones(X.shape[0])]  # Sabit terim (bias)\n",
    "        for d in range(1, self.degree + 1):\n",
    "            poly_features.append(X ** d)\n",
    "        return np.column_stack(poly_features)\n",
    "\n",
    "    def gradient_descent(self, X, y):\n",
    "        theta = np.random.randn(X.shape[1])\n",
    "        m = X.shape[0]\n",
    "\n",
    "        for iteration in range(self.iterations):\n",
    "            predictions = np.dot(X, theta)\n",
    "            errors = predictions - y\n",
    "            gradient = np.dot(X.T, errors) / m\n",
    "            theta_new = theta - self.lr * gradient\n",
    "            \n",
    "            if np.linalg.norm(theta_new - theta) < 1e-6:\n",
    "                print(f\"Converged at iteration {iteration}\")\n",
    "                break\n",
    "            \n",
    "            theta = theta_new\n",
    "        return theta\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_poly = self.create_polynomial_features(X)\n",
    "        if self.method == 'normal_equation':\n",
    "            self.weights = self.normal_equation(X_poly, y)\n",
    "        elif self.method == 'gradient_descent':\n",
    "            self.weights = self.gradient_descent(X_poly, y)\n",
    "        else:\n",
    "            raise ValueError(\"Method must be 'normal_equation' or 'gradient_descent'\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_poly = self.create_polynomial_features(X)\n",
    "        return np.dot(X_poly, self.weights)\n",
    "\n",
    "# Verileri yükleme ve hazırlama\n",
    "data = pd.read_csv('processed_dataset.csv')\n",
    "\n",
    "# Kategorik değişkeni sayısal değere dönüştürme\n",
    "le = LabelEncoder()\n",
    "data['city'] = le.fit_transform(data['city'])\n",
    "\n",
    "# Aykırı değerleri işleme\n",
    "def handle_outliers_iqr_all_columns(data):\n",
    "    for column_name in data.columns:\n",
    "        Q1 = data[column_name].quantile(0.25)  # Alt çeyrek (25. yüzdelik)\n",
    "        Q3 = data[column_name].quantile(0.75)  # Üst çeyrek (75. yüzdelik)\n",
    "        IQR = Q3 - Q1  # IQR hesaplama\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR  # Alt sınır\n",
    "        upper_bound = Q3 + 1.5 * IQR  # Üst sınır\n",
    "\n",
    "        # Alt sınırın altındaki ve üst sınırın üstündeki aykırı değerleri çeyrekler arası aralığa getirme\n",
    "        data[column_name] = data[column_name].apply(lambda x: lower_bound if x < lower_bound else (upper_bound if x > upper_bound else x))\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = handle_outliers_iqr_all_columns(data)\n",
    "\n",
    "# Özellik ve hedef değişkenleri ayırma\n",
    "X = data.drop(columns=['opened_inside_year','carried_over_from','finished','carried_over_to']).values\n",
    "y = data['opened_inside_year'].values\n",
    "\n",
    "# Verileri normalleştirme\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA uygulama\n",
    "pca = PCA(n_components=5)  # Kaç bileşen kullanılacak\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# PCA sonrası bileşenlerin dağılımını kontrol etme\n",
    "print(\"PCA sonrası bileşenlerin dağılımı:\")\n",
    "print(X_pca[:10])  # İlk 10 örneğin bileşen değerlerini yazdırma\n",
    "\n",
    "# Veriyi eğitim ve test setlerine ayırma\n",
    "# İlk 81 satır 2021 yılına aittir\n",
    "X_train, X_test, y_train, y_test = X_pca[81:], X_pca[:81], y[81:], y[:81]\n",
    "\n",
    "# Gradient Descent ile model oluşturma ve eğitme\n",
    "# Öğrenme oranını daha küçük bir değere ayarlandı\n",
    "model_gd = PolynomialRegression(degree=2, method='gradient_descent', lr=0.01, iterations=1000)\n",
    "model_gd.fit(X_train, y_train)\n",
    "\n",
    "# Tahminler\n",
    "y_pred_gd = model_gd.predict(X_test)\n",
    "\n",
    "# İlk 10 satır için tahmin edilen ve gerçek y değerlerini yazdırma (gradient descent)\n",
    "print(\"Gradient Descent Predictions:\")\n",
    "for i in range(10):\n",
    "    print(\"Predicted:\", y_pred_gd[i], \"\\tReal:\", y_test[i])\n",
    "\n",
    "# Her tahmin için mutlak yüzde hatasını hesaplama (gradient descent)\n",
    "absolute_percentage_errors_gd = np.abs((y_test - y_pred_gd) / y_test)\n",
    "\n",
    "# Ortalama mutlak yüzde hatasını hesaplama (gradient descent)\n",
    "mape_gd = np.mean(absolute_percentage_errors_gd)\n",
    "\n",
    "# MAPE'yi doğruluğa dönüştürme (gradient descent)\n",
    "accuracy_gd = 1 - mape_gd\n",
    "\n",
    "# Doğruluğu yüzdeye dönüştürme (gradient descent)\n",
    "percentage_accuracy_gd = accuracy_gd * 100\n",
    "\n",
    "print(\"Average Percentage Accuracy (Gradient Descent):\", percentage_accuracy_gd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ae3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
